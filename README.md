# Web Scraping y ETL: AnÃ¡lisis de Libros

Este proyecto realiza un proceso completo de **ExtracciÃ³n, TransformaciÃ³n y Carga (ETL)** de datos de libros desde el sitio [Books to Scrape](https://books.toscrape.com/). El objetivo es obtener informaciÃ³n detallada sobre los libros, limpiarla y analizarla para obtener insights Ãºtiles.

---

## ğŸ“Œ DescripciÃ³n

El proyecto estÃ¡ diseÃ±ado para:

- **Extraer** datos de libros desde una pÃ¡gina web utilizando tÃ©cnicas de web scraping.
- **Transformar** los datos para limpiarlos y estructurarlos adecuadamente.
- **Cargar** los datos procesados en un formato adecuado para su anÃ¡lisis y visualizaciÃ³n.

---

## ğŸ› ï¸ TecnologÃ­as Usadas

- **Python 3**  
- **Selenium** â†’ AutomatizaciÃ³n del navegador y extracciÃ³n de datos.  
- **BeautifulSoup** â†’ Parseo y scraping de HTML.  
- **Pandas** â†’ Limpieza y manipulaciÃ³n de datos.  
- **NumPy** â†’ Operaciones numÃ©ricas y estadÃ­sticas.  
- **Matplotlib y Seaborn** â†’ VisualizaciÃ³n de datos.  
- **MySQL** (opcional) â†’ Carga de datos procesados a base de datos.  
- **Jupyter Notebook** â†’ AnÃ¡lisis exploratorio interactivo.

---

## ğŸ“‚ Estructura del Proyecto

```plaintext
Web-Scraping-y-ETL/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Datos crudos extraÃ­dos
â”‚   â””â”€â”€ processed/        # Datos procesados listos para anÃ¡lisis
â”œâ”€â”€ notebook/             # Jupyter Notebooks para anÃ¡lisis exploratorio
â”œâ”€â”€ src/                  # CÃ³digo fuente del scraper y procesamiento
â”‚   â”œâ”€â”€ extract.py        # Funciones para extracciÃ³n de datos
â”‚   â”œâ”€â”€ transform.py      # Funciones para transformaciÃ³n de datos
â”‚   â””â”€â”€ load.py           # Funciones para carga de datos
â”œâ”€â”€ .gitignore            # Archivos y carpetas a ignorar por Git
â”œâ”€â”€ requirements.txt      # Dependencias del proyecto
â””â”€â”€ README.md             # DocumentaciÃ³n del proyecto
```
## ğŸ› ï¸ Requisitos

Para ejecutar este proyecto, necesitas tener instaladas las siguientes dependencias:
`pip install -r requirements.txt`

## ğŸš€ Uso

- ExtracciÃ³n de datos: Ejecuta el script de extracciÃ³n para obtener los datos de los libros.
- TransformaciÃ³n de datos: Utiliza las funciones de transformaciÃ³n para limpiar y estructurar los datos.
- Carga de datos: Guarda los datos procesados en el formato deseado (CSV, base de datos, etc.).
- AnÃ¡lisis: Abre el notebook en notebook/ para realizar un anÃ¡lisis exploratorio y visualizar los datos.

## ğŸ“Š AnÃ¡lisis Exploratorio

En el Jupyter Notebook proporcionado, se realizan los siguientes anÃ¡lisis:

- DistribuciÃ³n de precios de los libros.
- RelaciÃ³n entre precio y rating.
- IdentificaciÃ³n de los libros mÃ¡s caros y mÃ¡s baratos.
- AnÃ¡lisis de la disponibilidad de los libros por categorÃ­a.
